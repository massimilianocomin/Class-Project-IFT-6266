#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Apr  4 13:26:13 2017

@author: mcomin
"""

import sys
import os
import glob
import pickle
import string
import PIL.Image as Image
import re

if os.environ['LOC'] == 'local':
    datapath = '/Network/Servers/seguin.pmc.umontreal.ca/Users/mcomin/inpainting'
    libpath = '../lib'
    filepath = os.getcwd()
elif os.environ['LOC'] == 'hades':
    datapath = 'data'
    libpath = '/home2/ift6ed13/lib'
    filepath = '/home2/ift6ed13/results'
sys.path.append(libpath)

import numpy as np
import matplotlib.pyplot as plt
import theano
import theano.tensor as T
from Layers import *

theano.config.floatX = 'float32'
theano.config.intX = 'int32'

class Loader:
    """
    Images and caption loader.
    """
    
    def __init__(self):
        
        # Images
        
        with open(libpath+'/SKIP_NAMES','rb') as file:
            self.IMG_TO_SKIP = pickle.load(file)

        self.IMG_TO_SKIP = [k[16:] for k in self.IMG_TO_SKIP]

        trainlist = glob.glob(datapath+'/train/*.jpg')
        validlist = glob.glob(datapath+'/valid/*.jpg')
        
        self.trainlist = np.array([x for x in trainlist if x not in self.IMG_TO_SKIP])
        self.validlist = np.array([x for x in validlist if x not in self.IMG_TO_SKIP])
        
        self.namelist = {'train':self.trainlist,'valid':self.validlist}
        
        # Captions

        with open(datapath + '/dict_key_imgID_value_caps_train_and_valid.pkl','rb') as f :
            self.caption = pickle.load(f)
        
        with open(libpath + '/Word2Vec','rb') as f:
            self.wordict = pickle.load(f)
        
    
    def get_batch(self,batchsize,i,mode):
        """
        Mini-batch Generator.
        """
        
        names = self.namelist[mode]
        batch_list = names[i*batchsize:(i+1)*batchsize]
        capt_list = ['COCO' + re.search('COCO(.+?).jpg',i).group(1) for i in batch_list] # Regular expression
            
        img = [np.array(Image.open(fname)) for fname in batch_list]
        img = np.array(img,dtype=theano.config.floatX)/256.
        img = img.transpose(0,3,1,2)

        img_crop = np.copy(img)
        img_crop[:,:,16:48,16:48] = 0

        captions = self.build_captions(capt_list)
                  
        return img_crop, img[:,:,16:48,16:48], captions, np.array(capt_list)


    def build_captions(self,namelist):
        """
        Loads captions from namelist, convert it to word embedding (size 200),
        and zero-pads to the maximum size.
        """
        
        convert = lambda x : x.translate(str.maketrans('','',string.punctuation)).split()
        
        n = np.random.randint(0,5) # Random caption over the 5 available
        
        max_len = max([len(convert(self.caption[name][n])) for name in namelist])
        
        captions = []
        
        for name in namelist:
            
            vec_of_string = convert(self.caption[name][n])
            
            vec_of_vec = []
            
            for k in vec_of_string:
                try:
                    vec_of_vec.append(self.wordict[k])
                except KeyError:
                    continue

            while len(vec_of_vec) < max_len:
                vec_of_vec.append(np.zeros(200))
            
            captions.append(vec_of_vec)

        return np.array(captions,dtype=theano.config.floatX)
    
    def plot(self,image,save=False):
        
        if type(image) == str or type(image) == np.str_:
            
            tv = '/train/' if 'train' in image else '/valid/'
            img = np.array(Image.open(datapath + tv + image + '.jpg'))
            caption = self.caption[image][np.random.randint(0,5)]
            
            plt.xlabel(caption)
            plt.imshow(img)
            
        else:
            image = image.transpose(1,2,0)
            plt.axis("off")
            plt.imshow(image)
        
        if save:
            plt.savefig(save+'.png')

class Model(Loader):
    """
    Implementation of a Conditional Least Squares Generative Adversarial Network.
    
    Generator : 
        - Takes High dimentional noise + cropped image + captions as input
        - As in DCGAN : relu activations, no pooling, strides instead.
        - Add Skip Connections ?
        - Gaussian noise at last layer ?
        
    Discriminator :
        - Takes a full image (true or cropped + generated center) + caption as input.
        - As in LSGAN : leaky relu activations, no pooling, strides instead.
    
    
    *** During Validation, Rebuild Model ***
    BatchNorm Layers with train_batch's mean and std
    Dropout Layers with train = False
    """
    def __init__(self,bs,n=None):
    
        print('Building computational graph...')
        
        Loader.__init__(self)
        self.bs = bs
        self.n = n
        self.trainlist = self.trainlist[0:n]

        self.name = 'FINAL'
        
        delta = 0.35 # Part of Image Metrics in Generator Loss
        teta = 0.85 # Part of SSIM in Image Metric
        l_rate = 1e-3 # Learning rate
        m_rate = 0.9 # Momentum parameter


        x = T.tensor4('crop')
        y = T.tensor4('center')
        z = T.tensor4('noise')
        c = T.tensor3('caption')
        c_fake = T.tensor3('caption_fake')
        s = T.scalar('smooth')

        g = self.G(x,z,c)
        d_real = self.D(x,y,c)
        d_gen = self.D(x,g,c)
        d_fake = self.D(x,y,c_fake)
        
        one = np.ones(self.bs) 
        zero = np.zeros(self.bs)

        # Discriminator Loss : One sided label smoothing (s)
        # Training D to set (real image, wrong caption) as fake.
        Dcost = ( Tool.Mse( d_real, s*one, dims=2 ) + Tool.Mse( d_gen, zero, dims=2 ) + 0.15*Tool.Mse(d_fake, zero, dims=2) )/3.

        # Generator Cost    
        Gcost = Tool.Mse( d_gen, one, dims=2 )/2. + delta*( (1.-teta)*Tool.Mae(g,y) + teta*Tool.DSSIM(g,y) )

        D_update = Tool.rmsprop_nesterov(Dcost, self.D_params, eta = l_rate, alpha = m_rate)
        G_update = Tool.rmsprop_momentum(Gcost, self.G_params, eta = l_rate/10., alpha = m_rate)


        self.train_D = theano.function([x,y,z,c,c_fake,s], Dcost, updates = D_update)
        self.train_G = theano.function([x,y,z,c], Gcost, updates = G_update)
        self.generator = theano.function([x,z,c], g)
        
        print('Computational graph built.')

    def D(self,x,y,c):
        
        D = {}
        x = x.reshape((x.shape[0],3,64,64))
        y = y.reshape((y.shape[0],3,32,32))
        img = T.set_subtensor(x[:,:,16:48,16:48], y)
        
        # s = 1 : Same size || s = 2 : size/2
        Conv = lambda x,y,z,s : ConvLayer(x, nchan = y, nkernels = z, kernelsize = (3,3),
                            activation = None, pad = 1, stride=(s,s))

        BN = lambda x,y : BatchNorm(x, y, activation = 'relux', dims = 4)
        
        Drop = lambda x : Dropout(x, drop = 0.3, train = True)

        Tconvargs = {'kernelsize':(2,2), 'W':None,'B':None, 'poolsize':(1,1),
                    'pad':0,'stride':(2,2), 'tied':False, 'batch':self.bs}

        # Captions pre process

        D['c0'] = InputLayer(c)
        
        D['c1'] = LSTMLayer(D['c0'], 200, 96, truncate = 10) # Out = (sentence size, 100)
        D['c2'] = OperatorLayer(D['c1'], T.mean, axis = 1) # Mean over time steps (seq length)
        
        D['c3'] = ReshapeLayer(D['c2'], (self.bs, 6, 4, 4))
        D['c4'] = TConvLayer(D['c3'], shape=(8,8), nchan=48, nkernels=6, activation='sigmoid', **Tconvargs)
        D['c5'] = ReshapeLayer(D['c4'], (self.bs, 3, 32, 32))
        D['c6'] = Conv(D['c5'], 3, 32, s = 1)

        # Model
        
        D[0] = InputLayer(img)
        
        D[1] = Conv(Drop(D[0]), 3, 32, s = 2) # Out = 32
        D[2] = BN(D[1], 32)
        
        D[3] = JoinLayer(D[2], D['c6'], axis = 1)
        
        D[4] = Conv(Drop(D[3]), 64, 96, s = 2) # Out = 16
        D[5] = BN(D[4], 96)
        
        D[6] = Conv(Drop(D[5]), 96, 128, s = 2) # Out = 8
        D[7] = BN(D[6], 128)
        
        D[8] = Conv(Drop(D[7]), 128, 192, s = 2) # Out = 4
        D[9] = BN(D[8], 192)
        
        D[10] = Conv(Drop(D[9]), 192, 256, s = 2) # Out = 2
        D[11] = BN(D[10], 256)
        
        D[12] = Conv(D[11], 256, 256, s = 1)
        D[13] = DenseLayer(D[12], 256*2*2, 1, activation = 'sigmoid') 
        
        self.D_params = [x for i in D.keys() for x in D[i].params]

        return D[13].output

    def G(self,x,z,c): 

        G = {}
        x = x.reshape((self.bs,3,64,64)) # Cropped image
        z = z.reshape((self.bs,3,64,64)) # Gaussian noise

        # s = 1 : Same size || s = 2 : size/2
        Conv = lambda x,y,z,s : ConvLayer(x, nchan = y, nkernels = z, kernelsize = (3,3),
                                    activation = None, pad = 1, stride=(s,s))

        BN = lambda x,y : BatchNorm(x, y, activation = 'relux', dims = 4)

        Drop = lambda x : Dropout(x, drop = 0.10, train = True)
        
        Sum = lambda x,y : SumLayer(x,InputLayer(self.Noise((self.bs,y,32,32))),ratio=0.5)


        # Captions
        
        Tconvargs = {'kernelsize':(2,2), 'W':None,'B':None, 'poolsize':(1,1),
                    'pad':0, 'stride':(2,2), 'tied':False, 'batch':self.bs}
        
        # Captions pre process

        G['c0'] = InputLayer(c)
        
        G['c1'] = LSTMLayer(G['c0'], 200, 96, truncate = 10) # Out = (sentence size, 100)
        G['c2'] = OperatorLayer(G['c1'], T.mean, axis = 1) # Mean over time steps (seq length)
        
        G['c3'] = ReshapeLayer(G['c2'], (self.bs, 6, 4, 4))
        G['c4'] = TConvLayer(G['c3'], shape=(8,8), nchan=48, nkernels=6, activation='sigmoid', **Tconvargs)
        
        G['c5'] = ReshapeLayer(G['c4'], (self.bs, 3, 32, 32))
        G['c6'] = Conv(G['c5'], 3, 64, s = 1)


        # Main branch

        G['image'] = InputLayer(x)
        G['noise'] = InputLayer(z)
        
        G[0] = JoinLayer(G['image'],G['noise'],axis = 1)
        
        G[1] = Conv(G[0], 6, 64, s = 2)
        G[2] = BN(G[1], 64)
        
        G[3] = JoinLayer(G[2], G['c6'], axis = 1) # Out = (bs, 128, 32, 32)
        
        G[4] = Conv(Drop(Sum(G[3], 128)) , 128, 64, s = 1)
        G[5] = BN(G[4], 64)
        
        G[6] = Conv(Drop(Sum(G[5], 64)) , 64, 32, s = 1) 
        G[7] = BN(G[6], 32)
        
        G[8] = Conv(Drop(Sum(G[7], 32)), 32, 16, s = 1)
        G[9] = BN(G[8], 16)
        
        G[10] = ConvLayer(Drop(Sum(G[9], 16)), nchan=16, nkernels=3, kernelsize=(3,3), activation='sigmoid', pad=1)

        self.G_params = [x for i in G.keys() for x in G[i].params]

        return G[10].output


    def Train(self,epochs=1, save=True):
        
        Dloss = np.zeros((epochs,self.n // self.bs))
        Gloss = np.zeros((epochs,self.n // self.bs))

        for i in range(epochs):
            
            with Tool.Timer() as t:
                
                for j in range(self.n // self.bs):
                    
                    # Inputs
                    crop, center, captions, _ = self.get_batch(self.bs,j,'train')
                    z = self.Noise((self.bs,3,64,64))
                    
                    # Fake captions (taken randomly from validation set)
                    rand = np.random.randint(0,200)
                    rand_names = self.namelist['valid'][rand*self.bs:(rand+1)*self.bs]
                    capt_names = ['COCO' + re.search('COCO(.+?).jpg',i).group(1) for i in rand_names]
                    fake_captions = self.build_captions(capt_names)
                    
                    # Random smoothing
                    s = np.random.normal(0.85,0.1)
                    
                    # Training !
                    Dloss[i,j] = self.train_D(crop, center, z, captions, fake_captions, s)
                    Gloss[i,j] = self.train_G(crop, center, z, captions)
            
            string = 'Epoch {0} ## Discriminator Loss : {1:.6} ## Generator Loss : {2:.6} ## Time : {3:.2} s'
            print(string.format(i+1,float(Dloss[i,-1]),float(Gloss[i,-1]),t.interval))

            if ((i+1)%5 == 0 or i+1 == epochs) and save:
                self.Generate('train')
                self.Generate('valid')
                self.__save__(str(i+1))
        
        # Save all losses : 
        
        losses = {'G':Gloss,'D':Dloss}
        with open(filepath + '/' + self.name + '_LOSS','wb') as f:
            pickle.dump(losses, f, 2)
            
    def Generate(self,mode,n=0):
        
        crop,_,captions,names = self.get_batch(self.bs,n,mode=mode)
        z = self.Noise((self.bs,3,64,64))
        
        base = np.copy(crop)
        pred = np.array(self.generator(crop,z,captions))

        base[:,:,16:48,16:48] += pred

        if mode == 'train':
            self.train_recon = base,names
        elif mode == 'valid':
            self.valid_recon = base, names

    def Noise(self,size):
        return np.random.normal(0.,1.,size = size).astype(theano.config.floatX)
    
    def __save__(self,epoch):
        
        directory = filepath+'/'+self.name
        
        G_numpy_params = [self.G_params[k].get_value() for k in range(len(self.G_params))]
        D_numpy_params = [self.D_params[k].get_value() for k in range(len(self.D_params))]
        
        with open(directory + '_G_params_' + epoch,'wb') as file:
            pickle.dump(G_numpy_params,file, 2)

        with open(directory + '_D_params_' + epoch,'wb') as file:
            pickle.dump(D_numpy_params,file, 2)

        for i in range(15):
            
            with open(directory + '_train/' + epoch + '_' + str(i), 'wb') as file:
                pickle.dump(self.train_recon[0][i], file, 2)
                
            with open(directory + '_valid/' + epoch + '_' + str(i), 'wb') as file:
                pickle.dump(self.valid_recon[0][i], file, 2)
        
        with open(directory + '_train/' + 'train_names.txt','wb') as file:
            pickle.dump(self.train_recon[1][0:15], file)
        with open(directory + '_valid/' + 'valid_names.txt','wb') as file:
            pickle.dump(self.valid_recon[1][0:15], file)


    def __load__(self,epoch):
        
        with open(filepath+'/'+self.name+'_G_params_' + epoch,'rb') as file:
            G_loaded_params = pickle.load(file)
            
        for k in range(len(self.G_params)):
            self.G_params[k].set_value(G_loaded_params[k])

        with open(filepath+'/'+self.name+'_D_params_' + epoch,'rb') as file:
            D_loaded_params = pickle.load(file)
            
        for k in range(len(self.D_params)):
            self.D_params[k].set_value(D_loaded_params[k])


